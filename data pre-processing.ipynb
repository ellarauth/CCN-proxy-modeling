{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['ABZ', 'ALE', 'AMA', 'AMM', 'ASP', 'BEI', 'BOT', 'BSL', 'DEL', 'EGB',\n",
    "          'HAD', 'HEL', 'HPB', 'HYY', 'KCE', 'KPZ', 'MAR', 'MHD', 'MLP', 'MUK', \n",
    "          'NAN', 'NEU', 'POV', 'SAO', 'SCH', 'SGP', 'UAE', 'VAR', 'VIE', 'WAL', \n",
    "          'ZOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_datasets(folder):\n",
    "    full_df = []\n",
    "\n",
    "    for c in cities:\n",
    "        df = pd.read_csv('data/'+folder+'/'+c+'.csv')\n",
    "        df['station'] = c\n",
    "        full_df.append(df)\n",
    "\n",
    "    full_df = pd.concat(full_df)\n",
    "    full_df = full_df.reset_index(drop=True)\n",
    "    full_df['id'] = [full_df.station[i] + '-' + str(full_df.date[i]) for i in range(full_df.shape[0])]\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerosols_df = combine_datasets('aerosols')\n",
    "aerosols_df = aerosols_df[['id', 'latitude', 'longitude',\n",
    "                           'aermr01', 'aermr02', 'aermr03','aermr04', 'aermr05',\n",
    "                           'aermr06', 'aermr07', 'aermr08',  'aermr09', 'aermr10']]\n",
    "# exclude 'aermr11' for now so that there is still data for AMA\n",
    "\n",
    "aerosols_df.to_csv('data/aerosols_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmospheric_df = combine_datasets('atmospheric')\n",
    "atmospheric_df = atmospheric_df[['id', 'd2m', 't2m']]\n",
    "\n",
    "atmospheric_df.to_csv('data/atomospheric_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_layer_height_df = combine_datasets('boundary_layer_height')\n",
    "boundary_layer_height_df = boundary_layer_height_df[['id', 'blh']]\n",
    "\n",
    "boundary_layer_height_df.to_csv('data/boundary_layer_height_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "gases_df = combine_datasets('gases')\n",
    "gases_df = gases_df[['id', 'co', 'c5h8', 'no2', 'no', 'so2']]\n",
    "\n",
    "gases_df.to_csv('data/gases_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_access_df = combine_datasets('slow_access')\n",
    "slow_access_df = slow_access_df[['id', 'nh3', 'crwc', 'c10h16']]\n",
    "slow_access_df.to_csv('data/slow_access_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "n100_df = []\n",
    "\n",
    "for c in cities:\n",
    "    df = pd.read_table('data/N100_proxy/'+c+'_N100.dat', sep='\\s+', \n",
    "                       names=['year', 'month', 'day', 'hour', 'minute', 'n100'])\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "    \n",
    "    # AMA and UAE are in UTC, so the times of the measurements need to be adjusted to local time\n",
    "    if (c == 'AMA'):\n",
    "        df['time'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.time -= timedelta(hours=4)\n",
    "        df = df.drop(columns='time')\n",
    "    elif (c == 'UAE'):\n",
    "        df['time'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.time += timedelta(hours=4)\n",
    "        df = df.drop(columns='time')\n",
    "    \n",
    "    df = df.groupby('date', as_index=False).mean()\n",
    "    df.date = df.date.dt.date\n",
    "    df['station'] = c\n",
    "    n100_df.append(df)\n",
    "\n",
    "n100_df = pd.concat(n100_df)\n",
    "n100_df = n100_df.reset_index(drop=True)\n",
    "n100_df['id'] = [n100_df.station[i] + '-' + str(n100_df.date[i]) for i in range(n100_df.shape[0])]\n",
    "n100_df = n100_df[['id', 'station', 'date', 'n100']]\n",
    "n100_df.to_csv('data/n100_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the data sets into one data frame\n",
    "data = n100_df.merge(aerosols_df, on='id')\n",
    "data = data.merge(atmospheric_df, on='id')\n",
    "data = data.merge(boundary_layer_height_df, on='id')\n",
    "data = data.merge(gases_df, on='id')\n",
    "data = data.merge(slow_access_df, on='id')\n",
    "\n",
    "data.date = pd.to_datetime(data.date)\n",
    "data = data.dropna(axis=0)\n",
    "data.to_csv('data/full_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
