{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the measurement station codes (35 stations)\n",
    "# more detailed information on the stations can be found in metadata/measurement_sites_info.txt\n",
    "stations = ['ABZ', 'ALE', 'AMA', 'AMM', 'ASP', 'BEI', 'BOT', 'BSL', 'DEL', 'EGB',\n",
    "            'FKL', 'HAD', 'HEL', 'HPB', 'HRW', 'HYY', 'KCE', 'KPZ', 'MAR', 'MHD', \n",
    "            'MLP', 'MUK', 'NAN', 'NEU', 'POV', 'SAO', 'SCH', 'SGP', 'UAE', 'PRL',\n",
    "            'VAR', 'VHL', 'VIE', 'WAL', 'ZOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_datasets(folder):\n",
    "    '''\n",
    "    Concatenates the individual datasets for all measurement stations in a specified folder located in \"data/\".\n",
    "    \n",
    "    Parameters:\n",
    "    folder (str): Name of folder located in the \"data/\" folder of the repository\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: data frame of the concatenated data sets in the folder\n",
    "    '''\n",
    "    \n",
    "    full_df = []\n",
    "\n",
    "    for s in stations:\n",
    "        df = pd.read_csv('data/'+folder+'/'+s+'.csv')\n",
    "        df['station'] = s\n",
    "        full_df.append(df)\n",
    "\n",
    "    full_df = pd.concat(full_df)\n",
    "    full_df = full_df.reset_index(drop=True)\n",
    "    full_df['id'] = [full_df.station[i] + '-' + str(full_df.date[i]) for i in range(full_df.shape[0])]\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the aerosol mixing ratio data and saving it as a separate csv file\n",
    "# a full description of all variable names can be found in metadata/variable_names.txt\n",
    "aerosols_df = combine_datasets('aerosols')\n",
    "aerosols_df = aerosols_df[['id', 'latitude', 'longitude', 'aermr01', 'aermr02', \n",
    "                           'aermr03', 'aermr04', 'aermr05', 'aermr06', 'aermr07', \n",
    "                           'aermr08', 'aermr09', 'aermr10', 'aermr11']]\n",
    "aerosols_df.to_csv('data/aerosols_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the atmospheric data, calculating the relative humidity, and saving it as a separate csv file\n",
    "atmospheric_df = combine_datasets('atmospheric')\n",
    "atmospheric_df = atmospheric_df[['id', 'd2m', 't2m']]\n",
    "td = atmospheric_df.d2m - 273.15\n",
    "t = atmospheric_df.t2m - 273.15\n",
    "atmospheric_df['rh'] = 100*(np.exp((17.625*td) / (243.04+td)) / np.exp((17.625*t) / (243.04+t)))\n",
    "atmospheric_df.to_csv('data/atmospheric_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the boundary layer height data and saving it as a separate csv file\n",
    "boundary_layer_height_df = combine_datasets('boundary_layer_height')\n",
    "boundary_layer_height_df = boundary_layer_height_df[['id', 'blh']]\n",
    "boundary_layer_height_df.to_csv('data/boundary_layer_height_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the gas data and saving it as a separate csv file\n",
    "gases_df = combine_datasets('gases')\n",
    "gases_df = gases_df[['id', 'co', 'c5h8', 'no2', 'no', 'so2']]\n",
    "gases_df.to_csv('data/gases_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the slow access data and saving it as a separate csv file\n",
    "slow_access_df = combine_datasets('slow_access')\n",
    "slow_access_df = slow_access_df[['id', 'nh3', 'crwc', 'c10h16']]\n",
    "slow_access_df.to_csv('data/slow_access_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the wind data, calculating the wind speed, and saving it as a separate csv file\n",
    "wind_df = combine_datasets('wind')\n",
    "wind_df['wind_speed'] = np.sqrt(wind_df.u**2 + wind_df.v**2)\n",
    "wind_df = wind_df[['id', 'wind_speed']]\n",
    "wind_df.to_csv('data/wind.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the n100 data and saving it as a separate csv file\n",
    "n100_df = []\n",
    "for s in stations:\n",
    "    df = pd.read_table('data/N100_proxy/'+s+'_N100.dat', sep='\\s+', \n",
    "                       names=['year', 'month', 'day', 'hour', 'minute', 'n100'])\n",
    "    \n",
    "    # AMA and UAE are in UTC, so the times of the measurements need to be adjusted to local time\n",
    "    if (s == 'AMA'):\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.date -= timedelta(hours=4)\n",
    "        df.date = [d.replace(hour=0, minute=0, second=0) for d in df.date]      \n",
    "    elif (s == 'UAE'):\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.date += timedelta(hours=4)\n",
    "        df.date = [d.replace(hour=0, minute=0, second=0) for d in df.date]\n",
    "        \n",
    "    # the year for FKL is multiplied by 2 due to some bug, so needs to be corrected\n",
    "    elif (s == 'FKL'):\n",
    "        df.year /= 2\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])  \n",
    "        \n",
    "    else:\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "        \n",
    "    df = df.groupby('date', as_index=False).mean()\n",
    "    df.date = df.date.dt.date\n",
    "    df['station'] = s\n",
    "    n100_df.append(df)\n",
    "\n",
    "n100_df = pd.concat(n100_df)\n",
    "n100_df = n100_df.reset_index(drop=True)\n",
    "n100_df['id'] = [n100_df.station[i] + '-' + str(n100_df.date[i]) for i in range(n100_df.shape[0])]\n",
    "n100_df = n100_df[['id', 'station', 'date', 'n100']]\n",
    "n100_df.to_csv('data/n100_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>doy_cos</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>n100</th>\n",
       "      <th>aermr01</th>\n",
       "      <th>aermr02</th>\n",
       "      <th>...</th>\n",
       "      <th>nh3</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>d2m</th>\n",
       "      <th>t2m</th>\n",
       "      <th>crwc</th>\n",
       "      <th>blh</th>\n",
       "      <th>rh</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABZ-2012-01-26</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>0.431673</td>\n",
       "      <td>0.902030</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2708.085714</td>\n",
       "      <td>6.752697e-12</td>\n",
       "      <td>5.765684e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>8.448101e-10</td>\n",
       "      <td>1.302913e-08</td>\n",
       "      <td>2.060121e-08</td>\n",
       "      <td>6.464830e-09</td>\n",
       "      <td>266.65186</td>\n",
       "      <td>268.37625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.51462</td>\n",
       "      <td>87.716470</td>\n",
       "      <td>1.228889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABZ-2012-01-27</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>0.447094</td>\n",
       "      <td>0.894487</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2489.175000</td>\n",
       "      <td>4.223335e-12</td>\n",
       "      <td>3.600730e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.008734e-09</td>\n",
       "      <td>1.489063e-08</td>\n",
       "      <td>2.199851e-08</td>\n",
       "      <td>7.113044e-09</td>\n",
       "      <td>265.71246</td>\n",
       "      <td>267.83536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.03300</td>\n",
       "      <td>85.013445</td>\n",
       "      <td>0.962691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABZ-2012-01-28</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>0.462383</td>\n",
       "      <td>0.886680</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3484.229167</td>\n",
       "      <td>3.553853e-12</td>\n",
       "      <td>3.007895e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407371e-09</td>\n",
       "      <td>3.310498e-08</td>\n",
       "      <td>1.887175e-08</td>\n",
       "      <td>7.495814e-09</td>\n",
       "      <td>268.29993</td>\n",
       "      <td>269.69257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.80160</td>\n",
       "      <td>90.074210</td>\n",
       "      <td>0.785850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABZ-2012-01-29</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>0.477536</td>\n",
       "      <td>0.878612</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2977.512500</td>\n",
       "      <td>8.665312e-12</td>\n",
       "      <td>7.307493e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.466395e-09</td>\n",
       "      <td>4.424891e-09</td>\n",
       "      <td>1.569601e-08</td>\n",
       "      <td>4.929475e-09</td>\n",
       "      <td>267.07495</td>\n",
       "      <td>269.08804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.47455</td>\n",
       "      <td>85.875228</td>\n",
       "      <td>1.748744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABZ-2012-01-30</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-30</td>\n",
       "      <td>0.492548</td>\n",
       "      <td>0.870285</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2702.463636</td>\n",
       "      <td>1.436837e-11</td>\n",
       "      <td>1.208825e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.477080e-09</td>\n",
       "      <td>1.021235e-09</td>\n",
       "      <td>1.345031e-08</td>\n",
       "      <td>5.219232e-09</td>\n",
       "      <td>263.61273</td>\n",
       "      <td>267.95770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>610.29910</td>\n",
       "      <td>71.525093</td>\n",
       "      <td>2.068425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id station       date   doy_sin   doy_cos  latitude  longitude  \\\n",
       "0  ABZ-2012-01-26     ABZ 2012-01-26  0.431673  0.902030     50.57      12.99   \n",
       "1  ABZ-2012-01-27     ABZ 2012-01-27  0.447094  0.894487     50.57      12.99   \n",
       "2  ABZ-2012-01-28     ABZ 2012-01-28  0.462383  0.886680     50.57      12.99   \n",
       "3  ABZ-2012-01-29     ABZ 2012-01-29  0.477536  0.878612     50.57      12.99   \n",
       "4  ABZ-2012-01-30     ABZ 2012-01-30  0.492548  0.870285     50.57      12.99   \n",
       "\n",
       "          n100       aermr01       aermr02  ...           nh3            no  \\\n",
       "0  2708.085714  6.752697e-12  5.765684e-10  ...  8.448101e-10  1.302913e-08   \n",
       "1  2489.175000  4.223335e-12  3.600730e-10  ...  1.008734e-09  1.489063e-08   \n",
       "2  3484.229167  3.553853e-12  3.007895e-10  ...  1.407371e-09  3.310498e-08   \n",
       "3  2977.512500  8.665312e-12  7.307493e-10  ...  1.466395e-09  4.424891e-09   \n",
       "4  2702.463636  1.436837e-11  1.208825e-09  ...  1.477080e-09  1.021235e-09   \n",
       "\n",
       "            no2           so2        d2m        t2m  crwc        blh  \\\n",
       "0  2.060121e-08  6.464830e-09  266.65186  268.37625   0.0  306.51462   \n",
       "1  2.199851e-08  7.113044e-09  265.71246  267.83536   0.0  142.03300   \n",
       "2  1.887175e-08  7.495814e-09  268.29993  269.69257   0.0  152.80160   \n",
       "3  1.569601e-08  4.929475e-09  267.07495  269.08804   0.0  461.47455   \n",
       "4  1.345031e-08  5.219232e-09  263.61273  267.95770   0.0  610.29910   \n",
       "\n",
       "          rh  wind_speed  \n",
       "0  87.716470    1.228889  \n",
       "1  85.013445    0.962691  \n",
       "2  90.074210    0.785850  \n",
       "3  85.875228    1.748744  \n",
       "4  71.525093    2.068425  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining all the data sets into one dataframe\n",
    "data = n100_df.merge(aerosols_df, on='id')\n",
    "data = data.merge(atmospheric_df, on='id')\n",
    "data = data.merge(boundary_layer_height_df, on='id')\n",
    "data = data.merge(gases_df, on='id')\n",
    "data = data.merge(slow_access_df, on='id')\n",
    "data = data.merge(wind_df, on='id')\n",
    "\n",
    "# calculating the day of the year (doy) adding the sine and cosine of the doy to the dataframe\n",
    "data['date'] =  pd.to_datetime(data['date'])\n",
    "doy = data.date.dt.dayofyear\n",
    "data['doy_sin'] = np.sin((2*np.pi*doy)/doy.max())\n",
    "data['doy_cos'] = np.cos((2*np.pi*doy)/doy.max())\n",
    "\n",
    "# removing outliers for VHL\n",
    "for i, row in data.loc[data.station == 'VHL'].iterrows():\n",
    "    if row.n100 > 10000:\n",
    "        data.drop(index=i, inplace=True)\n",
    "\n",
    "# reordering the columns\n",
    "data = data[['id', 'station', 'date', 'doy_sin', 'doy_cos', 'latitude', 'longitude', 'n100', \n",
    "             'aermr01', 'aermr02', 'aermr03', 'aermr04', 'aermr05', 'aermr06', 'aermr07', \n",
    "             'aermr08', 'aermr09', 'aermr10', 'aermr11', 'co', 'c5h8', 'c10h16', 'nh3', \n",
    "             'no', 'no2', 'so2', 'd2m', 't2m', 'crwc', 'blh', 'rh', 'wind_speed']]\n",
    "\n",
    "# saving the full dataset\n",
    "data.date = pd.to_datetime(data.date)\n",
    "data = data.dropna(axis=0)\n",
    "data.to_csv('data/full_data.csv', index=False)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
